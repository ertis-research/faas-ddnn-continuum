# DOCKER_PREFIX=192.168.43.7:30501 faas build -f inference.yml && DOCKER_PREFIX=192.168.43.7:30501 faas push -f inference.yml && DOCKER_PREFIX=10.10.32.10:30501 faas deploy -f inference.yml
version: 1.0
provider:
  name: openfaas
  gateway: http://192.168.43.7:31112
functions:
  kafka-exit-edge:
    lang: python3-http
    handler: ./kafka-funnel
    image: ${DOCKER_PREFIX:-registry.hub.docker.com}/kafka-funnel:latest
    label:
      com.openfaas.scale.max: 10
    environment:
      FUNNEL_TOPIC: openfaas.inference.edge-output
      FUNNEL_PRODUCER: >
        {
          "bootstrap_servers": [
            "kafka-0.kafka-headless.kafka:9092",
            "kafka-1.kafka-headless.kafka:9092",
            "kafka-2.kafka-headless.kafka:9092",
            "kafka-3.kafka-headless.kafka:9092",
            "kafka-4.kafka-headless.kafka:9092",
            "kafka-5.kafka-headless.kafka:9092"
          ]
        }

  kafka-exit-fog:
    lang: python3-http
    handler: ./kafka-funnel
    image: ${DOCKER_PREFIX:-registry.hub.docker.com}/kafka-funnel:latest
    environment:
      FUNNEL_TOPIC: openfaas.inference.fog-output
      FUNNEL_PRODUCER: >
        {
          "bootstrap_servers": [
            "kafka-0.kafka-headless.kafka:9092",
            "kafka-1.kafka-headless.kafka:9092",
            "kafka-2.kafka-headless.kafka:9092",
            "kafka-3.kafka-headless.kafka:9092",
            "kafka-4.kafka-headless.kafka:9092",
            "kafka-5.kafka-headless.kafka:9092"
          ]
        }

  kafka-exit-cloud:
    lang: python3-http
    handler: ./kafka-funnel
    image: ${DOCKER_PREFIX:-registry.hub.docker.com}/kafka-funnel:latest
    label:
      com.openfaas.scale.max: 10
    environment:
      FUNNEL_TOPIC: openfaas.inference.cloud-output
      FUNNEL_PRODUCER: >
        {
          "bootstrap_servers": [
            "kafka-0.kafka-headless.kafka:9092",
            "kafka-1.kafka-headless.kafka:9092",
            "kafka-2.kafka-headless.kafka:9092",
            "kafka-3.kafka-headless.kafka:9092",
            "kafka-4.kafka-headless.kafka:9092",
            "kafka-5.kafka-headless.kafka:9092"
          ]
        }

  inference-edge:
    lang: python3-http-tensor
    handler: ./inference
    image: ${DOCKER_PREFIX:-registry.hub.docker.com}/inference:latest
    label:
      com.openfaas.scale.max: 20
      com.openfaas.scale.factor: 50%
    environment:
      MODEL: "function/edge.h5"
      EXIT_URL: http://gateway.openfaas:8080/async-function/kafka-exit-edge
      NEXT_URL: http://gateway.openfaas:8080/async-function/inference-fog
      NEXT_CONFIDENCE: .65

      write_timeout: 10m
      read_timeout: 10m
      exec_timeout: 10m
      handler_wait_duration: 10m
      healthcheck_interval: 5s

    limits:
      cpu: 4000m
      memory: 1024Mi
    requests:
      cpu: 4000m
      memory: 1024Mi

  inference-fog:
    lang: python3-http-tensor
    handler: ./inference
    image: ${DOCKER_PREFIX:-registry.hub.docker.com}/inference:latest
    label:
      com.openfaas.scale.max: 20
      com.openfaas.scale.factor: 50%
    environment:
      MODEL: "function/fog.h5"
      EXIT_URL: http://gateway.openfaas:8080/async-function/kafka-exit-fog
      NEXT_URL: http://gateway.openfaas:8080/async-function/inference-cloud
      NEXT_CONFIDENCE: .50

      write_timeout: 10m
      read_timeout: 10m
      exec_timeout: 10m
      handler_wait_duration: 10m
      healthcheck_interval: 5s

    limits:
      cpu: 4000m
      memory: 1024Mi
    requests:
      cpu: 4000m
      memory: 1024Mi

  inference-cloud:
    lang: python3-http-tensor
    handler: ./inference
    image: ${DOCKER_PREFIX:-registry.hub.docker.com}/inference:latest
    label:
      com.openfaas.scale.max: 20
      com.openfaas.scale.factor: 50%
    environment:
      MODEL: "function/cloud.h5"
      EXIT_URL: http://gateway.openfaas:8080/async-function/kafka-exit-cloud

      write_timeout: 10m
      read_timeout: 10m
      exec_timeout: 10m
      handler_wait_duration: 10m
      healthcheck_interval: 5s

    limits:
      cpu: 4000m
      memory: 1024Mi
    requests:
      cpu: 4000m
      memory: 1024Mi

  inference-test:
    lang: python3-http-tensor
    handler: ./inference
    image: ${DOCKER_PREFIX:-registry.hub.docker.com}/inference:latest
    label:
      com.openfaas.scale.max: 10
    environment:
      MODEL: "function/test.h5"
      EXIT_URL: http://gateway.openfaas:8080/async-function/kafka-funnel

      write_timeout: 10m
      read_timeout: 10m
      exec_timeout: 10m
      handler_wait_duration: 10m
      healthcheck_interval: 5s

    limits:
      cpu: 4000m
      memory: 1024Mi
    requests:
      cpu: 4000m
      memory: 1024Mi
